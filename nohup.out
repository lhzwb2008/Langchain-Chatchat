Traceback (most recent call last):
  File "/root/Langchain-Chatchat/startup.py", line 39, in <module>
    from server.knowledge_base.migrate import create_tables
  File "/root/Langchain-Chatchat/server/knowledge_base/migrate.py", line 11, in <module>
    from server.knowledge_base.kb_service.base import KBServiceFactory
  File "/root/Langchain-Chatchat/server/knowledge_base/kb_service/base.py", line 10, in <module>
    from server.db.repository.knowledge_base_repository import (
  File "/root/Langchain-Chatchat/server/db/repository/__init__.py", line 1, in <module>
    from .conversation_repository import *
  File "/root/Langchain-Chatchat/server/db/repository/conversation_repository.py", line 1, in <module>
    from server.db.session import with_session
  File "/root/Langchain-Chatchat/server/db/session.py", line 3, in <module>
    from server.db.base import SessionLocal
  File "/root/Langchain-Chatchat/server/db/base.py", line 1, in <module>
    from sqlalchemy import create_engine
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/sqlalchemy/__init__.py", line 13, in <module>
    from .engine import AdaptedConnection as AdaptedConnection
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/sqlalchemy/engine/__init__.py", line 18, in <module>
    from . import events as events
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/sqlalchemy/engine/events.py", line 19, in <module>
    from .base import Connection
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 30, in <module>
    from .interfaces import BindTyping
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/sqlalchemy/engine/interfaces.py", line 38, in <module>
    from ..sql.compiler import Compiled as Compiled
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/sqlalchemy/sql/__init__.py", line 10, in <module>
    from ._typing import ColumnExpressionArgument as ColumnExpressionArgument
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/sqlalchemy/sql/_typing.py", line 281, in <module>
    _TypeEngineArgument = Union[Type["TypeEngine[_T]"], "TypeEngine[_T]"]
                                ~~~~^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/typing.py", line 362, in inner
    return cached(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/typing.py", line 1575, in __getitem__
    params = tuple(_type_check(p, msg) for p in params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/typing.py", line 1575, in <genexpr>
    params = tuple(_type_check(p, msg) for p in params)
                   ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/typing.py", line 186, in _type_check
    arg = _type_convert(arg, module=module, allow_special_forms=allow_special_forms)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/typing.py", line 164, in _type_convert
    return ForwardRef(arg, module=module, is_class=allow_special_forms)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/typing.py", line 864, in __init__
    code = compile(arg_to_compile, '<string>', 'eval')
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
2024-03-05 15:00:49,288 - startup.py[line:651] - INFO: 正在启动服务：
2024-03-05 15:00:49,288 - startup.py[line:652] - INFO: 如需查看 llm_api 日志，请前往 /root/Langchain-Chatchat/logs


==============================Langchain-Chatchat Configuration==============================
操作系统：Linux-4.19.0-14-amd64-x86_64-with-glibc2.31.
python版本：3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]
项目版本：v0.0.1
langchain版本：0.0.354. fastchat版本：0.2.35


当前使用的分词器：ChineseRecursiveTextSplitter
当前启动的LLM模型：['chatglm3-6b'] @ cuda
{'device': 'cuda',
 'host': '0.0.0.0',
 'infer_turbo': False,
 'model_path': 'chatglm3-6b',
 'model_path_exists': True,
 'port': 20002}
当前Embbedings模型： bge-large-zh @ cuda
==============================Langchain-Chatchat Configuration==============================


2024-03-05 15:00:54 | ERROR | stderr | INFO:     Started server process [41976]
2024-03-05 15:00:54 | ERROR | stderr | INFO:     Waiting for application startup.
2024-03-05 15:00:54 | ERROR | stderr | INFO:     Application startup complete.
2024-03-05 15:00:54 | ERROR | stderr | INFO:     Uvicorn running on http://0.0.0.0:20000 (Press CTRL+C to quit)
2024-03-05 15:00:54 | INFO | model_worker | Loading the model ['chatglm3-6b'] on worker a69163e3 ...
2024-03-05 15:00:54 | WARNING | transformers_modules.THUDM.chatglm3-6b.9addbe01105ca1939dd60a0e5866a1812be9daea.tokenization_chatglm | Setting eos_token is not supported, use the default one.
2024-03-05 15:00:54 | WARNING | transformers_modules.THUDM.chatglm3-6b.9addbe01105ca1939dd60a0e5866a1812be9daea.tokenization_chatglm | Setting pad_token is not supported, use the default one.
2024-03-05 15:00:54 | WARNING | transformers_modules.THUDM.chatglm3-6b.9addbe01105ca1939dd60a0e5866a1812be9daea.tokenization_chatglm | Setting unk_token is not supported, use the default one.
2024-03-05 15:00:55 | ERROR | stderr | Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]
2024-03-05 15:00:56 | ERROR | stderr | Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:04,  1.35it/s]
2024-03-05 15:00:56 | ERROR | stderr | Loading checkpoint shards:  29%|██▊       | 2/7 [00:01<00:03,  1.29it/s]
2024-03-05 15:00:57 | ERROR | stderr | Loading checkpoint shards:  43%|████▎     | 3/7 [00:02<00:03,  1.29it/s]
2024-03-05 15:00:58 | ERROR | stderr | Loading checkpoint shards:  57%|█████▋    | 4/7 [00:03<00:02,  1.31it/s]
2024-03-05 15:00:59 | ERROR | stderr | Loading checkpoint shards:  71%|███████▏  | 5/7 [00:03<00:01,  1.28it/s]
2024-03-05 15:00:59 | ERROR | stderr | Loading checkpoint shards:  86%|████████▌ | 6/7 [00:04<00:00,  1.28it/s]
2024-03-05 15:01:00 | ERROR | stderr | Loading checkpoint shards: 100%|██████████| 7/7 [00:05<00:00,  1.47it/s]
2024-03-05 15:01:00 | ERROR | stderr | Loading checkpoint shards: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]
2024-03-05 15:01:00 | ERROR | stderr | 
2024-03-05 15:01:04 | INFO | model_worker | Register to controller
INFO:     Started server process [42273]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:7861 (Press CTRL+C to quit)

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.

Traceback (most recent call last):
  File "/root/miniconda3/envs/yijing/bin/streamlit", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/streamlit/web/cli.py", line 233, in main_run
    _main_run(target, args, flag_options=kwargs)
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/streamlit/web/cli.py", line 269, in _main_run
    bootstrap.run(file, is_hello, args, flag_options)
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/streamlit/web/bootstrap.py", line 411, in run
    _install_pages_watcher(main_script_path)
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/streamlit/web/bootstrap.py", line 386, in _install_pages_watcher
    watch_dir(
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/streamlit/watcher/path_watcher.py", line 153, in watch_dir
    return _watch_path(
           ^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/streamlit/watcher/path_watcher.py", line 128, in _watch_path
    watcher_class(
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/streamlit/watcher/event_based_path_watcher.py", line 92, in __init__
    path_watcher.watch_path(
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/streamlit/watcher/event_based_path_watcher.py", line 170, in watch_path
    folder_handler.watch = self._observer.schedule(
                           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/watchdog/observers/api.py", line 301, in schedule
    emitter.start()
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/watchdog/utils/__init__.py", line 92, in start
    self.on_thread_start()
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/watchdog/observers/inotify.py", line 119, in on_thread_start
    self._inotify = InotifyBuffer(path, self.watch.is_recursive)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/watchdog/observers/inotify_buffer.py", line 37, in __init__
    self._inotify = Inotify(path, recursive)
                    ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/watchdog/observers/inotify_c.py", line 179, in __init__
    self._add_dir_watch(path, recursive, event_mask)
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/watchdog/observers/inotify_c.py", line 395, in _add_dir_watch
    self._add_watch(path, mask)
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/watchdog/observers/inotify_c.py", line 416, in _add_watch
    Inotify._raise_error()
  File "/root/miniconda3/envs/yijing/lib/python3.11/site-packages/watchdog/observers/inotify_c.py", line 428, in _raise_error
    raise OSError(errno.ENOSPC, "inotify watch limit reached")
OSError: [Errno 28] inotify watch limit reached
2024-03-05 15:03:57,988 - startup.py[line:856] - WARNING: Sending SIGKILL to {}
2024-03-05 15:03:57,988 - startup.py[line:856] - WARNING: Sending SIGKILL to {'chatglm3-6b': <Process name='model_worker - chatglm3-6b (41977)' pid=41977 parent=41673 started daemon>}
2024-03-05 15:03:57,988 - startup.py[line:856] - WARNING: Sending SIGKILL to <Process name='controller (41842)' pid=41842 parent=41673 started daemon>
2024-03-05 15:03:57,989 - startup.py[line:856] - WARNING: Sending SIGKILL to <Process name='openai_api (41976)' pid=41976 parent=41673 started daemon>
2024-03-05 15:03:57,990 - startup.py[line:856] - WARNING: Sending SIGKILL to <Process name='API Server (42273)' pid=42273 parent=41673 started daemon>
2024-03-05 15:03:57,990 - startup.py[line:856] - WARNING: Sending SIGKILL to <Process name='WEBUI Server (42430)' pid=42430 parent=41673 stopped exitcode=0 daemon>
2024-03-05 15:03:57,990 - startup.py[line:867] - INFO: Process status: {}
2024-03-05 15:03:57,990 - startup.py[line:867] - INFO: Process status: {'chatglm3-6b': <Process name='model_worker - chatglm3-6b (41977)' pid=41977 parent=41673 started daemon>}
2024-03-05 15:03:57,990 - startup.py[line:867] - INFO: Process status: <Process name='controller (41842)' pid=41842 parent=41673 started daemon>
2024-03-05 15:03:57,990 - startup.py[line:867] - INFO: Process status: <Process name='openai_api (41976)' pid=41976 parent=41673 started daemon>
2024-03-05 15:03:57,990 - startup.py[line:867] - INFO: Process status: <Process name='API Server (42273)' pid=42273 parent=41673 started daemon>
2024-03-05 15:03:57,990 - startup.py[line:867] - INFO: Process status: <Process name='WEBUI Server (42430)' pid=42430 parent=41673 stopped exitcode=0 daemon>


==============================Langchain-Chatchat Configuration==============================
操作系统：Linux-4.19.0-14-amd64-x86_64-with-glibc2.31.
python版本：3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]
项目版本：v0.0.1
langchain版本：0.0.354. fastchat版本：0.2.35


当前使用的分词器：ChineseRecursiveTextSplitter
当前启动的LLM模型：['chatglm3-6b'] @ cuda
{'device': 'cuda',
 'host': '0.0.0.0',
 'infer_turbo': False,
 'model_path': 'chatglm3-6b',
 'model_path_exists': True,
 'port': 20002}
当前Embbedings模型： bge-large-zh @ cuda


服务端运行信息：
    OpenAI API Server: http://127.0.0.1:20000/v1
    Chatchat  API  Server: http://127.0.0.1:7861
    Chatchat WEBUI Server: http://0.0.0.0:8501
==============================Langchain-Chatchat Configuration==============================


Traceback (most recent call last):
  File "/root/Langchain-Chatchat/startup.py", line 883, in <module>
    loop.run_until_complete(start_main_server())
  File "/root/miniconda3/envs/yijing/lib/python3.11/asyncio/base_events.py", line 640, in run_until_complete
    self.run_forever()
  File "/root/miniconda3/envs/yijing/lib/python3.11/asyncio/base_events.py", line 607, in run_forever
    self._run_once()
  File "/root/miniconda3/envs/yijing/lib/python3.11/asyncio/base_events.py", line 1922, in _run_once
    handle._run()
  File "/root/miniconda3/envs/yijing/lib/python3.11/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/root/Langchain-Chatchat/startup.py", line 779, in start_main_server
    cmd = queue.get() # 收到切换模型的消息
          ^^^^^^^^^^^
  File "<string>", line 2, in get
  File "/root/miniconda3/envs/yijing/lib/python3.11/multiprocessing/managers.py", line 822, in _callmethod
    kind, result = conn.recv()
                   ^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
          ^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/multiprocessing/connection.py", line 430, in _recv_bytes
    buf = self._recv(4)
          ^^^^^^^^^^^^^
  File "/root/miniconda3/envs/yijing/lib/python3.11/multiprocessing/connection.py", line 395, in _recv
    chunk = read(handle, remaining)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/Langchain-Chatchat/startup.py", line 609, in f
    raise KeyboardInterrupt(f"{signalname} received")
KeyboardInterrupt: SIGTERM received
/root/miniconda3/envs/yijing/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
